{\rtf1\ansi\ansicpg1252\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 /Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/bin/python /Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/src/mwe_metaphor/main.py \
mps\
MAX_LEN = 90\
len of sents in mwe adj processing 6568\
len(sentences)=252\
max_len of tokenized texts: 105\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
fold number 1:\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]Train loss: 0.691065422126225\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:18<01:13, 18.45s/it]Train loss: 0.6832945602280753\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:36<00:54, 18.05s/it]Train loss: 0.6715992263385228\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:53<00:35, 17.87s/it]Train loss: 0.6321389589990888\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:11<00:17, 17.78s/it]Train loss: 0.5166857583182198\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:29<00:00, 17.85s/it]\
scores.accuracy()=0.5769230769230769\
scores.precision_recall_fscore()=(0.6477272727272727, 0.576923076923077, 0.5193277310924369)\
fold number 2:\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]Train loss: 0.6982930813516889\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:17<01:10, 17.74s/it]Train loss: 0.6922232764107841\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:35<00:53, 17.71s/it]Train loss: 0.6884386454309736\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:52<00:35, 17.63s/it]Train loss: 0.635895162820816\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:10<00:17, 17.64s/it]Train loss: 0.5569978675671986\
scores.accuracy()=0.6538461538461539\
scores.precision_recall_fscore()=(0.5833333333333333, 0.5261437908496732, 0.48115299334811523)\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:28<00:00, 17.67s/it]\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 3:\
Train loss: 0.6995511821338108\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:17<01:10, 17.74s/it]Train loss: 0.6961665664400373\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:35<00:52, 17.62s/it]Train loss: 0.6703674495220184\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:52<00:35, 17.55s/it]Train loss: 0.6374642763819013\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:10<00:17, 17.50s/it]Train loss: 0.5367966251713889\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:27<00:00, 17.53s/it]\
scores.accuracy()=0.6\
scores.precision_recall_fscore()=(0.5476190476190476, 0.5416666666666666, 0.5404411764705883)\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 4:\
Train loss: 0.6936900658266885\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:17<01:10, 17.52s/it]Train loss: 0.6793425125735146\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:35<00:52, 17.55s/it]Train loss: 0.6805998938424247\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:52<00:35, 17.55s/it]Train loss: 0.6291697238172803\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:10<00:17, 17.59s/it]Train loss: 0.5330813888992582\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:27<00:00, 17.57s/it]\
scores.accuracy()=0.56\
scores.precision_recall_fscore()=(0.5608974358974359, 0.5608974358974359, 0.5599999999999999)\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 5:\
Train loss: 0.6952024698257446\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:17<01:09, 17.50s/it]Train loss: 0.683668430362429\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:35<00:52, 17.55s/it]Train loss: 0.6694834572928292\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:52<00:35, 17.52s/it]Train loss: 0.6269976539271218\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:10<00:17, 17.56s/it]Train loss: 0.5141225840364184\
scores.accuracy()=0.56\
scores.precision_recall_fscore()=(0.6071428571428572, 0.5876623376623377, 0.548440065681445)\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:27<00:00, 17.56s/it]\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 6:\
Train loss: 0.6974345658506665\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:17<01:10, 17.53s/it]Train loss: 0.679659115416663\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:35<00:52, 17.54s/it]Train loss: 0.6648770911352975\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:52<00:35, 17.67s/it]Train loss: 0.5970729887485504\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:10<00:17, 17.72s/it]Train loss: 0.3787108340433666\
scores.accuracy()=0.48\
scores.precision_recall_fscore()=(0.4891304347826087, 0.4967948717948718, 0.38095238095238093)\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:31<00:00, 18.33s/it]\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 7:\
Train loss: 0.6896688001496452\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:34<02:16, 34.24s/it]Train loss: 0.6825503919805799\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [01:20<02:04, 41.33s/it]Train loss: 0.6560354062489101\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [01:49<01:10, 35.48s/it]Train loss: 0.6229902165276664\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [02:11<00:30, 30.31s/it]Train loss: 0.5197787774460656\
scores.accuracy()=0.48\
scores.precision_recall_fscore()=(0.48333333333333334, 0.48397435897435903, 0.4766505636070854)\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [02:31<00:00, 30.24s/it]\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 8:\
Train loss: 0.6977180668285915\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:18<01:13, 18.38s/it]Train loss: 0.6768978365830013\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:36<00:54, 18.18s/it]Train loss: 0.6542413532733917\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:53<00:35, 17.90s/it]Train loss: 0.616683725799833\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:12<00:17, 17.96s/it]Train loss: 0.509246438741684\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:31<00:00, 18.20s/it]\
scores.accuracy()=0.6\
scores.precision_recall_fscore()=(0.6145833333333333, 0.6057692307692308, 0.5941558441558442)\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 9:\
Train loss: 0.693862476519176\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:18<01:14, 18.59s/it]Train loss: 0.6789148535047259\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:37<00:56, 18.72s/it]Train loss: 0.654381343296596\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:55<00:36, 18.38s/it]Train loss: 0.6246153563261032\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:12<00:18, 18.04s/it]Train loss: 0.44155553196157726\
scores.accuracy()=0.6\
scores.precision_recall_fscore()=(0.5543478260869565, 0.5166666666666667, 0.45175438596491224)\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:30<00:00, 18.09s/it]\
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\
  warnings.warn(\
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]fold number 10:\
Train loss: 0.6869602501392365\
Epoch:  20%|\uc0\u9608 \u9608         | 1/5 [00:17<01:10, 17.68s/it]Train loss: 0.6850004409040723\
Epoch:  40%|\uc0\u9608 \u9608 \u9608 \u9608       | 2/5 [00:35<00:52, 17.65s/it]Train loss: 0.6791278762476785\
Epoch:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608     | 3/5 [00:52<00:35, 17.63s/it]Train loss: 0.6166121321065086\
Epoch:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 4/5 [01:10<00:17, 17.62s/it]Train loss: 0.5303897580930165\
scores.accuracy()=0.4\
scores.precision_recall_fscore()=(0.3214285714285714, 0.35, 0.3315508021390374)\
K-fold cross-validation results:\
Accuracy: 0.5510769230769231\
Precision: 0.5409543445684749\
Recall: 0.5246498436204319\
F-score: 0.48844259434118464\
####\
recorded_results_per_fold= [(0.5769230769230769, 0.6477272727272727, 0.576923076923077, 0.5193277310924369), (0.6538461538461539, 0.5833333333333333, 0.5261437908496732, 0.48115299334811523), (0.6, 0.5476190476190476, 0.5416666666666666, 0.5404411764705883), (0.56, 0.5608974358974359, 0.5608974358974359, 0.5599999999999999), (0.56, 0.6071428571428572, 0.5876623376623377, 0.548440065681445), (0.48, 0.4891304347826087, 0.4967948717948718, 0.38095238095238093), (0.48, 0.48333333333333334, 0.48397435897435903, 0.4766505636070854), (0.6, 0.6145833333333333, 0.6057692307692308, 0.5941558441558442), (0.6, 0.5543478260869565, 0.5166666666666667, 0.45175438596491224), (0.4, 0.3214285714285714, 0.35, 0.3315508021390374)]\
len(set(recorded_results_per_fold))= 10\
Epoch: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 5/5 [01:28<00:00, 17.63s/it]\
\
Process finished with exit code 0}