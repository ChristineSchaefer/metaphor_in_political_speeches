/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/bin/python /Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/src/mwe_metaphor/controller/bert_training_controller.py
Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 10/1233 [00:31<1:02:46,  3.08s/it]{'loss': 1.782, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.02}
  2%|▏         | 20/1233 [01:01<1:00:07,  2.97s/it]{'loss': 1.7756, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.05}
  2%|▏         | 30/1233 [01:31<59:16,  2.96s/it]{'loss': 1.6956, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.07}
  3%|▎         | 40/1233 [07:30<3:41:25, 11.14s/it]{'loss': 1.5921, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.1}
  4%|▍         | 50/1233 [08:00<1:04:42,  3.28s/it]{'loss': 1.4645, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.12}
  5%|▍         | 60/1233 [08:31<1:00:28,  3.09s/it]{'loss': 1.343, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.15}
  6%|▌         | 70/1233 [09:02<59:33,  3.07s/it]{'loss': 1.1297, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.17}
  6%|▋         | 80/1233 [09:33<59:02,  3.07s/it]{'loss': 0.9285, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.19}
  7%|▋         | 90/1233 [10:03<58:12,  3.06s/it]{'loss': 0.7045, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.22}
  8%|▊         | 100/1233 [10:34<58:10,  3.08s/it]{'loss': 0.4632, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.24}
  9%|▉         | 110/1233 [11:05<57:26,  3.07s/it]{'loss': 0.2584, 'learning_rate': 4.4e-06, 'epoch': 0.27}
 10%|▉         | 120/1233 [11:35<56:47,  3.06s/it]{'loss': 0.094, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.29}
 11%|█         | 130/1233 [12:06<56:55,  3.10s/it]{'loss': 0.0276, 'learning_rate': 5.2e-06, 'epoch': 0.32}
 11%|█▏        | 140/1233 [12:37<56:31,  3.10s/it]{'loss': 0.0164, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.34}
 12%|█▏        | 150/1233 [13:08<55:24,  3.07s/it]{'loss': 0.0132, 'learning_rate': 6e-06, 'epoch': 0.36}
 13%|█▎        | 160/1233 [13:39<54:27,  3.05s/it]{'loss': 0.0128, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.39}
 14%|█▍        | 170/1233 [14:09<53:55,  3.04s/it]{'loss': 0.0114, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.41}
 15%|█▍        | 180/1233 [14:40<53:37,  3.06s/it]{'loss': 0.01, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.44}
 15%|█▌        | 190/1233 [15:10<53:14,  3.06s/it]{'loss': 0.0094, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.46}
 16%|█▌        | 200/1233 [15:41<53:07,  3.09s/it]{'loss': 0.0085, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.49}
 17%|█▋        | 210/1233 [16:12<52:34,  3.08s/it]{'loss': 0.0091, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.51}
 18%|█▊        | 220/1233 [16:43<52:10,  3.09s/it]{'loss': 0.0075, 'learning_rate': 8.8e-06, 'epoch': 0.54}
 19%|█▊        | 230/1233 [17:14<52:07,  3.12s/it]{'loss': 0.0058, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.56}
 19%|█▉        | 240/1233 [17:44<51:09,  3.09s/it]{'loss': 0.0049, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.58}
 20%|██        | 250/1233 [18:15<50:33,  3.09s/it]{'loss': 0.0043, 'learning_rate': 1e-05, 'epoch': 0.61}
 21%|██        | 260/1233 [18:46<50:05,  3.09s/it]{'loss': 0.0025, 'learning_rate': 1.04e-05, 'epoch': 0.63}
 22%|██▏       | 270/1233 [19:17<49:15,  3.07s/it]{'loss': 0.0019, 'learning_rate': 1.0800000000000002e-05, 'epoch': 0.66}
 23%|██▎       | 280/1233 [19:48<48:40,  3.06s/it]{'loss': 0.0018, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.68}
 24%|██▎       | 290/1233 [20:19<49:05,  3.12s/it]{'loss': 0.0012, 'learning_rate': 1.16e-05, 'epoch': 0.71}
 24%|██▍       | 300/1233 [20:49<46:51,  3.01s/it]{'loss': 0.001, 'learning_rate': 1.2e-05, 'epoch': 0.73}
 25%|██▌       | 310/1233 [21:20<46:28,  3.02s/it]{'loss': 0.0007, 'learning_rate': 1.2400000000000002e-05, 'epoch': 0.75}
 26%|██▌       | 320/1233 [21:50<45:58,  3.02s/it]{'loss': 0.0007, 'learning_rate': 1.2800000000000001e-05, 'epoch': 0.78}
 27%|██▋       | 330/1233 [22:20<45:20,  3.01s/it]{'loss': 0.0005, 'learning_rate': 1.3200000000000002e-05, 'epoch': 0.8}
 28%|██▊       | 340/1233 [22:50<44:58,  3.02s/it]{'loss': 0.0005, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.83}
 28%|██▊       | 350/1233 [23:20<44:28,  3.02s/it]{'loss': 0.0004, 'learning_rate': 1.4e-05, 'epoch': 0.85}
 29%|██▉       | 360/1233 [23:51<43:41,  3.00s/it]{'loss': 0.0003, 'learning_rate': 1.4400000000000001e-05, 'epoch': 0.88}
 30%|███       | 370/1233 [24:21<43:22,  3.02s/it]{'loss': 0.0003, 'learning_rate': 1.48e-05, 'epoch': 0.9}
 31%|███       | 380/1233 [24:51<43:21,  3.05s/it]{'loss': 0.0004, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.92}
 32%|███▏      | 390/1233 [25:22<42:53,  3.05s/it]{'loss': 0.0002, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.95}
 32%|███▏      | 400/1233 [25:52<41:55,  3.02s/it]{'loss': 0.0002, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.97}
 33%|███▎      | 410/1233 [26:23<42:09,  3.07s/it]{'loss': 0.0002, 'learning_rate': 1.64e-05, 'epoch': 1.0}
 33%|███▎      | 411/1233 [26:24<36:23,  2.66s/it]
  0%|          | 0/10 [00:00<?, ?it/s]
 20%|██        | 2/10 [00:03<00:14,  1.81s/it]
 30%|███       | 3/10 [00:07<00:17,  2.56s/it]
 40%|████      | 4/10 [00:10<00:17,  2.96s/it]
 50%|█████     | 5/10 [00:14<00:16,  3.22s/it]
 60%|██████    | 6/10 [00:18<00:13,  3.37s/it]
 70%|███████   | 7/10 [00:21<00:10,  3.48s/it]
 80%|████████  | 8/10 [00:25<00:07,  3.53s/it]
 90%|█████████ | 9/10 [00:29<00:03,  3.55s/it]
100%|██████████| 10/10 [00:30<00:00,  2.95s/it]/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -100 seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no_metaphor seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: is_metaphor seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

 33%|███▎      | 411/1233 [27:05<36:23,  2.66s/it]
100%|██████████| 10/10 [00:36<00:00,  2.95s/it]
                                               {'eval_loss': 0.00020528084132820368, 'eval_precision': 0.2639269406392694, 'eval_recall': 0.22648902821316613, 'eval_f1': 0.2437789962041333, 'eval_accuracy': 0.9528394933554817, 'eval_runtime': 40.3998, 'eval_samples_per_second': 14.901, 'eval_steps_per_second': 0.248, 'epoch': 1.0}
 34%|███▍      | 420/1233 [27:35<51:07,  3.77s/it]{'loss': 0.0002, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.02}
 35%|███▍      | 430/1233 [28:05<40:45,  3.05s/it]{'loss': 0.0002, 'learning_rate': 1.72e-05, 'epoch': 1.05}
 36%|███▌      | 440/1233 [28:36<40:40,  3.08s/it]{'loss': 0.0001, 'learning_rate': 1.76e-05, 'epoch': 1.07}
 36%|███▋      | 450/1233 [29:07<40:30,  3.10s/it]{'loss': 0.0001, 'learning_rate': 1.8e-05, 'epoch': 1.09}
 37%|███▋      | 460/1233 [29:38<39:56,  3.10s/it]{'loss': 0.0001, 'learning_rate': 1.8400000000000003e-05, 'epoch': 1.12}
 38%|███▊      | 470/1233 [30:09<38:44,  3.05s/it]{'loss': 0.0002, 'learning_rate': 1.88e-05, 'epoch': 1.14}
 39%|███▉      | 480/1233 [30:40<38:29,  3.07s/it]{'loss': 0.0001, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.17}
 40%|███▉      | 490/1233 [31:11<37:16,  3.01s/it]{'loss': 0.0001, 'learning_rate': 1.9600000000000002e-05, 'epoch': 1.19}
 41%|████      | 500/1233 [31:41<37:00,  3.03s/it]{'loss': 0.0001, 'learning_rate': 2e-05, 'epoch': 1.22}
 41%|████▏     | 510/1233 [32:11<36:14,  3.01s/it]{'loss': 0.0001, 'learning_rate': 1.9727148703956344e-05, 'epoch': 1.24}
 42%|████▏     | 520/1233 [32:42<35:51,  3.02s/it]{'loss': 0.0001, 'learning_rate': 1.945429740791269e-05, 'epoch': 1.27}
 43%|████▎     | 530/1233 [33:12<35:08,  3.00s/it]{'loss': 0.0001, 'learning_rate': 1.9181446111869032e-05, 'epoch': 1.29}
 44%|████▍     | 540/1233 [33:42<34:37,  3.00s/it]{'loss': 0.0001, 'learning_rate': 1.8908594815825378e-05, 'epoch': 1.31}
 45%|████▍     | 550/1233 [34:12<34:16,  3.01s/it]{'loss': 0.0001, 'learning_rate': 1.863574351978172e-05, 'epoch': 1.34}
 45%|████▌     | 560/1233 [34:43<35:04,  3.13s/it]{'loss': 0.0001, 'learning_rate': 1.8362892223738066e-05, 'epoch': 1.36}
 46%|████▌     | 570/1233 [35:14<34:01,  3.08s/it]{'loss': 0.0001, 'learning_rate': 1.8090040927694408e-05, 'epoch': 1.39}
 47%|████▋     | 580/1233 [35:45<34:04,  3.13s/it]{'loss': 0.0001, 'learning_rate': 1.781718963165075e-05, 'epoch': 1.41}
 48%|████▊     | 590/1233 [36:16<33:00,  3.08s/it]{'loss': 0.0001, 'learning_rate': 1.7544338335607096e-05, 'epoch': 1.44}
 49%|████▊     | 600/1233 [36:46<32:11,  3.05s/it]{'loss': 0.0001, 'learning_rate': 1.727148703956344e-05, 'epoch': 1.46}
 49%|████▉     | 610/1233 [37:17<31:39,  3.05s/it]{'loss': 0.0001, 'learning_rate': 1.699863574351978e-05, 'epoch': 1.48}
 50%|█████     | 620/1233 [37:47<31:27,  3.08s/it]{'loss': 0.0001, 'learning_rate': 1.6725784447476127e-05, 'epoch': 1.51}
 51%|█████     | 630/1233 [38:18<30:36,  3.05s/it]{'loss': 0.0001, 'learning_rate': 1.6452933151432472e-05, 'epoch': 1.53}
 52%|█████▏    | 640/1233 [38:49<30:28,  3.08s/it]{'loss': 0.0001, 'learning_rate': 1.6180081855388815e-05, 'epoch': 1.56}
 53%|█████▎    | 650/1233 [39:20<30:48,  3.17s/it]{'loss': 0.0001, 'learning_rate': 1.590723055934516e-05, 'epoch': 1.58}
 54%|█████▎    | 660/1233 [39:50<28:42,  3.01s/it]{'loss': 0.0001, 'learning_rate': 1.5634379263301503e-05, 'epoch': 1.61}
 54%|█████▍    | 670/1233 [40:21<28:42,  3.06s/it]{'loss': 0.0001, 'learning_rate': 1.5361527967257845e-05, 'epoch': 1.63}
 55%|█████▌    | 680/1233 [40:51<27:34,  2.99s/it]{'loss': 0.0001, 'learning_rate': 1.5088676671214189e-05, 'epoch': 1.65}
 56%|█████▌    | 690/1233 [41:22<28:17,  3.13s/it]{'loss': 0.0, 'learning_rate': 1.4815825375170533e-05, 'epoch': 1.68}
 57%|█████▋    | 700/1233 [41:52<27:06,  3.05s/it]{'loss': 0.0, 'learning_rate': 1.4542974079126877e-05, 'epoch': 1.7}
 58%|█████▊    | 710/1233 [42:22<26:35,  3.05s/it]{'loss': 0.0001, 'learning_rate': 1.427012278308322e-05, 'epoch': 1.73}
 58%|█████▊    | 720/1233 [42:53<26:12,  3.06s/it]{'loss': 0.0001, 'learning_rate': 1.3997271487039565e-05, 'epoch': 1.75}
 59%|█████▉    | 730/1233 [43:23<25:44,  3.07s/it]{'loss': 0.0, 'learning_rate': 1.372442019099591e-05, 'epoch': 1.78}
 60%|██████    | 740/1233 [43:53<24:29,  2.98s/it]{'loss': 0.0, 'learning_rate': 1.3451568894952252e-05, 'epoch': 1.8}
 61%|██████    | 750/1233 [44:23<24:43,  3.07s/it]{'loss': 0.0, 'learning_rate': 1.3178717598908597e-05, 'epoch': 1.82}
 62%|██████▏   | 760/1233 [44:53<23:33,  2.99s/it]{'loss': 0.0, 'learning_rate': 1.290586630286494e-05, 'epoch': 1.85}
 62%|██████▏   | 770/1233 [45:23<22:59,  2.98s/it]{'loss': 0.0, 'learning_rate': 1.2633015006821284e-05, 'epoch': 1.87}
 63%|██████▎   | 780/1233 [45:53<22:31,  2.98s/it]{'loss': 0.0, 'learning_rate': 1.2360163710777626e-05, 'epoch': 1.9}
 64%|██████▍   | 790/1233 [46:23<22:04,  2.99s/it]{'loss': 0.0, 'learning_rate': 1.2087312414733972e-05, 'epoch': 1.92}
 65%|██████▍   | 800/1233 [46:54<22:20,  3.10s/it]{'loss': 0.0, 'learning_rate': 1.1814461118690314e-05, 'epoch': 1.95}
 66%|██████▌   | 810/1233 [47:25<21:12,  3.01s/it]{'loss': 0.0, 'learning_rate': 1.1541609822646658e-05, 'epoch': 1.97}
 67%|██████▋   | 820/1233 [47:56<21:43,  3.16s/it]{'loss': 0.0, 'learning_rate': 1.1268758526603004e-05, 'epoch': 2.0}
 67%|██████▋   | 822/1233 [48:01<18:55,  2.76s/it]
  0%|          | 0/10 [00:00<?, ?it/s]
 20%|██        | 2/10 [00:03<00:14,  1.84s/it]
 30%|███       | 3/10 [00:07<00:18,  2.58s/it]
 40%|████      | 4/10 [00:11<00:18,  3.04s/it]
 50%|█████     | 5/10 [00:14<00:16,  3.27s/it]
 60%|██████    | 6/10 [00:18<00:13,  3.37s/it]
 70%|███████   | 7/10 [00:21<00:10,  3.44s/it]
 80%|████████  | 8/10 [00:25<00:06,  3.48s/it]
 90%|█████████ | 9/10 [00:29<00:03,  3.51s/it]
100%|██████████| 10/10 [00:31<00:00,  3.04s/it]/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -100 seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no_metaphor seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: is_metaphor seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

 67%|██████▋   | 822/1233 [48:42<18:55,  2.76s/it]
100%|██████████| 10/10 [00:36<00:00,  3.04s/it]
                                               {'eval_loss': 5.529721238417551e-05, 'eval_precision': 0.31875658587987354, 'eval_recall': 0.23706896551724138, 'eval_f1': 0.2719101123595506, 'eval_accuracy': 0.9528589597176079, 'eval_runtime': 40.8195, 'eval_samples_per_second': 14.748, 'eval_steps_per_second': 0.245, 'epoch': 2.0}
 67%|██████▋   | 830/1233 [49:10<28:25,  4.23s/it]{'loss': 0.0, 'learning_rate': 1.0995907230559346e-05, 'epoch': 2.02}
 68%|██████▊   | 840/1233 [49:41<20:38,  3.15s/it]{'loss': 0.0, 'learning_rate': 1.072305593451569e-05, 'epoch': 2.04}
 69%|██████▉   | 850/1233 [50:11<19:26,  3.05s/it]{'loss': 0.0, 'learning_rate': 1.0450204638472034e-05, 'epoch': 2.07}
 70%|██████▉   | 860/1233 [50:42<19:02,  3.06s/it]{'loss': 0.0, 'learning_rate': 1.0177353342428378e-05, 'epoch': 2.09}
 71%|███████   | 870/1233 [51:12<17:49,  2.95s/it]{'loss': 0.0, 'learning_rate': 9.90450204638472e-06, 'epoch': 2.12}
 71%|███████▏  | 880/1233 [51:41<17:33,  2.99s/it]{'loss': 0.0, 'learning_rate': 9.631650750341064e-06, 'epoch': 2.14}
 72%|███████▏  | 890/1233 [52:12<17:33,  3.07s/it]{'loss': 0.0, 'learning_rate': 9.358799454297409e-06, 'epoch': 2.17}
 73%|███████▎  | 900/1233 [52:43<17:07,  3.09s/it]{'loss': 0.0, 'learning_rate': 9.085948158253753e-06, 'epoch': 2.19}
 74%|███████▍  | 910/1233 [53:13<16:23,  3.04s/it]{'loss': 0.0, 'learning_rate': 8.813096862210097e-06, 'epoch': 2.21}
 75%|███████▍  | 920/1233 [53:44<15:56,  3.06s/it]{'loss': 0.0, 'learning_rate': 8.540245566166439e-06, 'epoch': 2.24}
 75%|███████▌  | 930/1233 [54:14<15:19,  3.03s/it]{'loss': 0.0, 'learning_rate': 8.267394270122785e-06, 'epoch': 2.26}
 76%|███████▌  | 940/1233 [54:45<14:53,  3.05s/it]{'loss': 0.0, 'learning_rate': 7.994542974079129e-06, 'epoch': 2.29}
 77%|███████▋  | 950/1233 [55:15<14:05,  2.99s/it]{'loss': 0.0, 'learning_rate': 7.721691678035471e-06, 'epoch': 2.31}
 78%|███████▊  | 960/1233 [55:45<13:33,  2.98s/it]{'loss': 0.0, 'learning_rate': 7.448840381991815e-06, 'epoch': 2.34}
 79%|███████▊  | 970/1233 [56:14<13:03,  2.98s/it]{'loss': 0.0, 'learning_rate': 7.175989085948158e-06, 'epoch': 2.36}
 79%|███████▉  | 980/1233 [56:45<12:51,  3.05s/it]{'loss': 0.0, 'learning_rate': 6.903137789904503e-06, 'epoch': 2.38}
 80%|████████  | 990/1233 [57:15<12:00,  2.97s/it]{'loss': 0.0, 'learning_rate': 6.630286493860847e-06, 'epoch': 2.41}
 81%|████████  | 1000/1233 [57:45<12:04,  3.11s/it]{'loss': 0.0, 'learning_rate': 6.35743519781719e-06, 'epoch': 2.43}
 82%|████████▏ | 1010/1233 [58:16<11:26,  3.08s/it]{'loss': 0.0, 'learning_rate': 6.084583901773534e-06, 'epoch': 2.46}
 83%|████████▎ | 1020/1233 [58:47<10:49,  3.05s/it]{'loss': 0.0, 'learning_rate': 5.8117326057298775e-06, 'epoch': 2.48}
 84%|████████▎ | 1030/1233 [59:17<10:15,  3.03s/it]{'loss': 0.0, 'learning_rate': 5.5388813096862215e-06, 'epoch': 2.51}
 84%|████████▍ | 1040/1233 [59:48<09:39,  3.00s/it]{'loss': 0.0, 'learning_rate': 5.2660300136425655e-06, 'epoch': 2.53}
 85%|████████▌ | 1050/1233 [1:00:18<09:22,  3.07s/it]{'loss': 0.0, 'learning_rate': 4.993178717598909e-06, 'epoch': 2.55}
 86%|████████▌ | 1060/1233 [1:00:49<08:45,  3.03s/it]{'loss': 0.0, 'learning_rate': 4.720327421555253e-06, 'epoch': 2.58}
 87%|████████▋ | 1070/1233 [1:01:19<08:20,  3.07s/it]{'loss': 0.0, 'learning_rate': 4.447476125511597e-06, 'epoch': 2.6}
 88%|████████▊ | 1080/1233 [1:01:51<08:26,  3.31s/it]{'loss': 0.0, 'learning_rate': 4.17462482946794e-06, 'epoch': 2.63}
 88%|████████▊ | 1090/1233 [1:02:22<07:31,  3.16s/it]{'loss': 0.0, 'learning_rate': 3.901773533424284e-06, 'epoch': 2.65}
 89%|████████▉ | 1100/1233 [1:02:54<06:58,  3.15s/it]{'loss': 0.0, 'learning_rate': 3.6289222373806276e-06, 'epoch': 2.68}
 90%|█████████ | 1110/1233 [1:03:25<06:19,  3.09s/it]{'loss': 0.0, 'learning_rate': 3.356070941336972e-06, 'epoch': 2.7}
 91%|█████████ | 1120/1233 [1:03:55<05:38,  2.99s/it]{'loss': 0.0, 'learning_rate': 3.0832196452933156e-06, 'epoch': 2.73}
 92%|█████████▏| 1130/1233 [1:04:26<05:15,  3.07s/it]{'loss': 0.0, 'learning_rate': 2.8103683492496592e-06, 'epoch': 2.75}
 92%|█████████▏| 1140/1233 [1:04:56<04:37,  2.98s/it]{'loss': 0.0, 'learning_rate': 2.537517053206003e-06, 'epoch': 2.77}
 93%|█████████▎| 1150/1233 [1:05:26<04:16,  3.10s/it]{'loss': 0.0, 'learning_rate': 2.264665757162347e-06, 'epoch': 2.8}
 94%|█████████▍| 1160/1233 [1:05:57<03:42,  3.05s/it]{'loss': 0.0, 'learning_rate': 1.9918144611186905e-06, 'epoch': 2.82}
 95%|█████████▍| 1170/1233 [1:06:27<03:10,  3.02s/it]{'loss': 0.0, 'learning_rate': 1.7189631650750343e-06, 'epoch': 2.85}
 96%|█████████▌| 1180/1233 [1:06:57<02:43,  3.09s/it]{'loss': 0.0, 'learning_rate': 1.446111869031378e-06, 'epoch': 2.87}
 97%|█████████▋| 1190/1233 [1:07:28<02:12,  3.07s/it]{'loss': 0.0, 'learning_rate': 1.173260572987722e-06, 'epoch': 2.9}
 97%|█████████▋| 1200/1233 [1:07:59<01:38,  3.00s/it]{'loss': 0.0, 'learning_rate': 9.004092769440656e-07, 'epoch': 2.92}
 98%|█████████▊| 1210/1233 [1:08:29<01:08,  3.00s/it]{'loss': 0.0, 'learning_rate': 6.275579809004094e-07, 'epoch': 2.94}
 99%|█████████▉| 1220/1233 [1:08:59<00:38,  3.00s/it]{'loss': 0.0, 'learning_rate': 3.5470668485675315e-07, 'epoch': 2.97}
100%|█████████▉| 1230/1233 [1:09:29<00:08,  2.99s/it]{'loss': 0.0, 'learning_rate': 8.185538881309687e-08, 'epoch': 2.99}
100%|██████████| 1233/1233 [1:09:36<00:00,  2.58s/it]
  0%|          | 0/10 [00:00<?, ?it/s]
 20%|██        | 2/10 [00:03<00:14,  1.79s/it]
 30%|███       | 3/10 [00:07<00:17,  2.53s/it]
 40%|████      | 4/10 [00:10<00:17,  2.92s/it]
 50%|█████     | 5/10 [00:14<00:15,  3.16s/it]
 60%|██████    | 6/10 [00:17<00:13,  3.31s/it]
 70%|███████   | 7/10 [00:22<00:10,  3.58s/it]
 80%|████████  | 8/10 [00:25<00:07,  3.63s/it]
 90%|█████████ | 9/10 [00:29<00:03,  3.63s/it]
100%|██████████| 10/10 [00:31<00:00,  3.29s/it]/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -100 seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no_metaphor seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: is_metaphor seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

100%|██████████| 1233/1233 [1:10:18<00:00,  2.58s/it]
100%|██████████| 10/10 [00:37<00:00,  3.29s/it]
                                               {'eval_loss': 4.910830830340274e-05, 'eval_precision': 0.3203371970495258, 'eval_recall': 0.23824451410658307, 'eval_f1': 0.27325842696629216, 'eval_accuracy': 0.9528589597176079, 'eval_runtime': 41.9827, 'eval_samples_per_second': 14.339, 'eval_steps_per_second': 0.238, 'epoch': 3.0}
100%|██████████| 1233/1233 [1:10:20<00:00,  3.42s/it]
{'train_runtime': 4220.7904, 'train_samples_per_second': 4.668, 'train_steps_per_second': 0.292, 'train_loss': 0.10858786175464306, 'epoch': 3.0}

Process finished with exit code 0