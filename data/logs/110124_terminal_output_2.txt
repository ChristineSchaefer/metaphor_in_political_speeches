/Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/venv/bin/python /Users/christineschafer/Documents/Uni-Kram/Masterarbeit/Repos/metaphor_in_political_speeches/src/mwe_metaphor/controller/bert_training_controller.py
Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/1233 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
 33%|███▎      | 411/1233 [1:10:34<35:20,  2.58s/it]
  0%|          | 0/38 [00:00<?, ?it/s]
  5%|▌         | 2/38 [00:00<00:15,  2.26it/s]
  8%|▊         | 3/38 [00:01<00:21,  1.59it/s]
 11%|█         | 4/38 [00:02<00:24,  1.38it/s]
 13%|█▎        | 5/38 [00:03<00:25,  1.27it/s]
 16%|█▌        | 6/38 [00:04<00:26,  1.22it/s]
 18%|█▊        | 7/38 [00:05<00:26,  1.19it/s]
 21%|██        | 8/38 [00:06<00:25,  1.17it/s]
 24%|██▎       | 9/38 [00:07<00:25,  1.15it/s]
 26%|██▋       | 10/38 [00:08<00:24,  1.14it/s]
 29%|██▉       | 11/38 [00:08<00:23,  1.14it/s]
 32%|███▏      | 12/38 [00:09<00:22,  1.13it/s]
 34%|███▍      | 13/38 [00:10<00:22,  1.13it/s]
 37%|███▋      | 14/38 [00:11<00:21,  1.13it/s]
 39%|███▉      | 15/38 [00:12<00:20,  1.12it/s]
 42%|████▏     | 16/38 [00:13<00:19,  1.12it/s]
 45%|████▍     | 17/38 [00:14<00:18,  1.12it/s]
 47%|████▋     | 18/38 [00:15<00:17,  1.12it/s]
 50%|█████     | 19/38 [00:16<00:16,  1.12it/s]
 53%|█████▎    | 20/38 [00:16<00:16,  1.12it/s]
 55%|█████▌    | 21/38 [00:17<00:15,  1.12it/s]
 58%|█████▊    | 22/38 [00:18<00:14,  1.12it/s]
 61%|██████    | 23/38 [00:19<00:13,  1.12it/s]
 63%|██████▎   | 24/38 [00:20<00:12,  1.12it/s]
 66%|██████▌   | 25/38 [00:21<00:11,  1.12it/s]
 68%|██████▊   | 26/38 [00:22<00:10,  1.12it/s]
 71%|███████   | 27/38 [00:23<00:09,  1.12it/s]
 74%|███████▎  | 28/38 [00:24<00:08,  1.12it/s]
 76%|███████▋  | 29/38 [00:24<00:08,  1.12it/s]
 79%|███████▉  | 30/38 [00:25<00:07,  1.12it/s]
 82%|████████▏ | 31/38 [00:26<00:06,  1.12it/s]
 84%|████████▍ | 32/38 [00:27<00:05,  1.13it/s]
 87%|████████▋ | 33/38 [00:28<00:04,  1.12it/s]
 89%|████████▉ | 34/38 [00:29<00:03,  1.12it/s]
 92%|█████████▏| 35/38 [00:30<00:02,  1.12it/s]
 95%|█████████▍| 36/38 [00:31<00:01,  1.12it/s]
 97%|█████████▋| 37/38 [00:32<00:00,  1.13it/s]

 33%|███▎      | 411/1233 [1:11:07<35:20,  2.58s/it]
100%|██████████| 38/38 [00:33<00:00,  1.16it/s]
                                               {'eval_loss': 0.00019354587129782885, 'eval_runtime': 33.5864, 'eval_samples_per_second': 17.924, 'eval_steps_per_second': 1.131, 'epoch': 1.0}
 41%|████      | 500/1233 [1:15:31<35:55,  2.94s/it]{'loss': 0.1402, 'learning_rate': 2e-05, 'epoch': 1.22}
 67%|██████▋   | 822/1233 [1:50:10<17:53,  2.61s/it]
  0%|          | 0/38 [00:00<?, ?it/s]
  5%|▌         | 2/38 [00:00<00:16,  2.21it/s]
  8%|▊         | 3/38 [00:01<00:22,  1.57it/s]
 11%|█         | 4/38 [00:02<00:25,  1.36it/s]
 13%|█▎        | 5/38 [00:03<00:26,  1.26it/s]
 16%|█▌        | 6/38 [00:04<00:26,  1.20it/s]
 18%|█▊        | 7/38 [00:05<00:26,  1.17it/s]
 21%|██        | 8/38 [00:06<00:26,  1.15it/s]
 24%|██▎       | 9/38 [00:07<00:25,  1.14it/s]
 26%|██▋       | 10/38 [00:08<00:24,  1.13it/s]
 29%|██▉       | 11/38 [00:09<00:24,  1.12it/s]
 32%|███▏      | 12/38 [00:09<00:23,  1.11it/s]
 34%|███▍      | 13/38 [00:10<00:22,  1.11it/s]
 37%|███▋      | 14/38 [00:11<00:21,  1.11it/s]
 39%|███▉      | 15/38 [00:12<00:20,  1.11it/s]
 42%|████▏     | 16/38 [00:13<00:19,  1.11it/s]
 45%|████▍     | 17/38 [00:14<00:18,  1.11it/s]
 47%|████▋     | 18/38 [00:15<00:18,  1.11it/s]
 50%|█████     | 19/38 [00:16<00:17,  1.10it/s]
 53%|█████▎    | 20/38 [00:17<00:16,  1.10it/s]
 55%|█████▌    | 21/38 [00:18<00:15,  1.10it/s]
 58%|█████▊    | 22/38 [00:19<00:14,  1.10it/s]
 61%|██████    | 23/38 [00:19<00:13,  1.11it/s]
 63%|██████▎   | 24/38 [00:20<00:12,  1.11it/s]
 66%|██████▌   | 25/38 [00:21<00:11,  1.11it/s]
 68%|██████▊   | 26/38 [00:22<00:10,  1.11it/s]
 71%|███████   | 27/38 [00:23<00:09,  1.11it/s]
 74%|███████▎  | 28/38 [00:24<00:09,  1.11it/s]
 76%|███████▋  | 29/38 [00:25<00:08,  1.11it/s]
 79%|███████▉  | 30/38 [00:26<00:07,  1.11it/s]
 82%|████████▏ | 31/38 [00:27<00:06,  1.11it/s]
 84%|████████▍ | 32/38 [00:28<00:05,  1.11it/s]
 87%|████████▋ | 33/38 [00:28<00:04,  1.11it/s]
 89%|████████▉ | 34/38 [00:29<00:03,  1.11it/s]
 92%|█████████▏| 35/38 [00:30<00:02,  1.11it/s]
 95%|█████████▍| 36/38 [00:31<00:01,  1.11it/s]
 97%|█████████▋| 37/38 [00:32<00:00,  1.11it/s]

 67%|██████▋   | 822/1233 [1:50:44<17:53,  2.61s/it]
100%|██████████| 38/38 [00:33<00:00,  1.15it/s]
                                               {'eval_loss': 4.828254532185383e-05, 'eval_runtime': 34.0949, 'eval_samples_per_second': 17.657, 'eval_steps_per_second': 1.115, 'epoch': 2.0}
 81%|████████  | 1000/1233 [1:59:47<11:53,  3.06s/it]{'loss': 0.0001, 'learning_rate': 6.35743519781719e-06, 'epoch': 2.43}
100%|██████████| 1233/1233 [2:11:42<00:00,  2.58s/it]
  0%|          | 0/38 [00:00<?, ?it/s]
  5%|▌         | 2/38 [00:00<00:16,  2.19it/s]
  8%|▊         | 3/38 [00:01<00:22,  1.55it/s]
 11%|█         | 4/38 [00:02<00:25,  1.35it/s]
 13%|█▎        | 5/38 [00:03<00:26,  1.26it/s]
 16%|█▌        | 6/38 [00:04<00:26,  1.20it/s]
 18%|█▊        | 7/38 [00:05<00:26,  1.16it/s]
 21%|██        | 8/38 [00:06<00:26,  1.13it/s]
 24%|██▎       | 9/38 [00:07<00:25,  1.12it/s]
 26%|██▋       | 10/38 [00:08<00:25,  1.11it/s]
 29%|██▉       | 11/38 [00:09<00:24,  1.10it/s]
 32%|███▏      | 12/38 [00:10<00:24,  1.08it/s]
 34%|███▍      | 13/38 [00:11<00:23,  1.05it/s]
 37%|███▋      | 14/38 [00:12<00:23,  1.04it/s]
 39%|███▉      | 15/38 [00:13<00:21,  1.05it/s]
 42%|████▏     | 16/38 [00:13<00:20,  1.06it/s]
 45%|████▍     | 17/38 [00:14<00:19,  1.06it/s]
 47%|████▋     | 18/38 [00:15<00:18,  1.06it/s]
 50%|█████     | 19/38 [00:16<00:17,  1.06it/s]
 53%|█████▎    | 20/38 [00:17<00:16,  1.07it/s]
 55%|█████▌    | 21/38 [00:18<00:15,  1.08it/s]
 58%|█████▊    | 22/38 [00:19<00:14,  1.08it/s]
 61%|██████    | 23/38 [00:20<00:13,  1.07it/s]
 63%|██████▎   | 24/38 [00:21<00:13,  1.08it/s]
 66%|██████▌   | 25/38 [00:22<00:12,  1.06it/s]
 68%|██████▊   | 26/38 [00:23<00:11,  1.06it/s]
 71%|███████   | 27/38 [00:24<00:10,  1.07it/s]
 74%|███████▎  | 28/38 [00:25<00:09,  1.08it/s]
 76%|███████▋  | 29/38 [00:26<00:08,  1.09it/s]
 79%|███████▉  | 30/38 [00:26<00:07,  1.09it/s]
 82%|████████▏ | 31/38 [00:27<00:06,  1.09it/s]
 84%|████████▍ | 32/38 [00:28<00:05,  1.10it/s]
 87%|████████▋ | 33/38 [00:29<00:04,  1.10it/s]
 89%|████████▉ | 34/38 [00:30<00:03,  1.10it/s]
 92%|█████████▏| 35/38 [00:31<00:02,  1.11it/s]
 95%|█████████▍| 36/38 [00:32<00:01,  1.11it/s]
 97%|█████████▋| 37/38 [00:33<00:00,  1.12it/s]

100%|██████████| 1233/1233 [2:12:17<00:00,  2.58s/it]
100%|██████████| 38/38 [00:34<00:00,  1.15it/s]
                                               {'eval_loss': 4.1031817090697587e-05, 'eval_runtime': 34.8079, 'eval_samples_per_second': 17.295, 'eval_steps_per_second': 1.092, 'epoch': 3.0}
100%|██████████| 1233/1233 [2:12:19<00:00,  6.44s/it]
{'train_runtime': 7939.5557, 'train_samples_per_second': 2.482, 'train_steps_per_second': 0.155, 'train_loss': 0.056869233454617654, 'epoch': 3.0}
100%|██████████| 38/38 [00:33<00:00,  1.14it/s]
{'eval_loss': 4.1031817090697587e-05, 'eval_runtime': 33.5798, 'eval_samples_per_second': 17.927, 'eval_steps_per_second': 1.132, 'epoch': 3.0}

Process finished with exit code 0
